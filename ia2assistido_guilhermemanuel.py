# -*- coding: utf-8 -*-
"""IA2assistido_guilhermemanuel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IKy4v5p5OWjKftZPEhKIzAZ55R34tyZP
"""

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, optimizers, datasets
from matplotlib import pyplot as plt
import numpy as np

(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = datasets.mnist.load_data()

print(x_train_raw.shape, y_train_raw.shape)
print(x_test_raw.shape, y_test_raw.shape)
print(x_train_raw[0])
print(y_train_raw[0])

#conversao de rotulos em variaveis
num_classes = 10
y_train = keras.utils.to_categorical(y_train_raw, num_classes)
y_test = keras.utils.to_categorical(y_test_raw, num_classes)
print(y_train_raw[0])
print(y_train[0])

plt.figure()
for i in range(9):
  plt.subplot(3, 3, i + 1)
  plt.imshow(x_train_raw[i])
  plt.axis('off')
plt.show()

# conversao de uma matriz(imagem) de 28x28 pra um vetor de 784 sem perder informação
x_train = x_train_raw.reshape(60000, 784)
x_test = x_test_raw.reshape(10000, 784)

#normalizar valores dos pixels
x_train = x_train.astype('float32')/255
x_test = x_test.astype('float32')/255

# criar um modelo de rede neural profunda(DNN) com tres camadas conectadas
model = keras.Sequential([
    layers.Dense(512, activation='relu', input_dim= 784),
    layers.Dense(256, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])
model.summary()

Optimizer = optimizers.Adam(0.001)
model.compile(loss=keras.losses.categorical_crossentropy, optimizer=Optimizer, metrics=['accuracy'])

#ajuste de dados de treinamento ao modelo e chamando o metodo fit para treino
history = model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), verbose=1)

#avaliacao modelo DNN
score= model.evaluate(x_test, y_test, verbose=0)
print('Perda do teste: ', score[0])
print('Acurácia do teste: ', score[1])

model.save('./model/final_DNN_model.h5')

from tensorflow.keras.models import load_model
new_model = load_model('./model/final_DNN_model.h5')
new_model.summary()

new_score = new_model.evaluate(x_test, y_test, verbose=0)
print('Perda do teste: ', new_score[0])
print('Acurácia do teste: ', new_score[1])

# Histórico de acurácia do modelo entre as epocas e o gráfico de perdas

#plotar acurácia
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Treinamento')
plt.plot(history.history['val_accuracy'], label='Validação')
plt.title('Acurácia por Época')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()

#plotar a perda
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Treinamento')
plt.plot(history.history['val_loss'], label='Validação')
plt.title('Perda por Época')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()

plt.tight_layout()
plt.show()

# gerar predict e avaliar com matriz de confusão

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

#Obter previsoes do modelo
y_pred_prob = model.predict(x_test) # retorna probabilidades

#converter para rótulos preditos
y_pred = np.argmax(y_pred_prob, axis=1)

#converter rótulos reais (se estiverem one-hot encoded )
y_true = np.argmax(y_test, axis=1)

#gerar matriz de confusao
cm = confusion_matrix(y_true, y_pred)

#exibir a matriz de confusao com rotulos
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title('Matriz de confusão')
plt.show()

#gerar acuracia, precisao, cobertura, f1, cohen kappa, prf e roc

y_pred_prob = model.predict(x_test)   #probabilidades
y_pred = np.argmax(y_pred_prob, axis=1)   #rotulos previstos
y_true = np.argmax(y_test, axis=1)

from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, classification_report, roc_curve, auc, roc_auc_score)
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize

#Acurácia
acc = accuracy_score(y_true, y_pred)
print(f"Acurácia:, {acc:.4f}")

#Precisão, recall e f1 (macro = média das classes)
prec = precision_score(y_true, y_pred, average='macro')
rec = recall_score(y_true, y_pred, average='macro')
f1 = f1_score(y_true, y_pred, average='macro')
print(f"Precisão (macro): {prec:.4f}")
print(f"Recall (macro): {rec:.4f}")
print(f"F1-score (macro): {f1:.4f}")

#cohen kappa
kappa = cohen_kappa_score(y_true, y_pred)
print(f"Cohen Kappa: {kappa:.4f}")

#relatorio completo (prf por classe)
print("\nRelatório de Classificação:\n")
print(classification_report(y_true, y_pred))

#binarizar os rotulos para ROC multiclasse
n_classes = y_pred_prob.shape[1]
y_true_bin = label_binarize(y_true, classes=range(n_classes))

#calcular ROC e AUC para cada classe
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
  fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])
  roc_auc[i] = auc(fpr[i], tpr[i])

#plotar curvas ROC
plt.figure(figsize=(10, 8))
for i in range(n_classes):
  plt.plot(fpr[i], tpr[i], label=f'Classe {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--') #linha de referencia
plt.xlabel('Falso positivo')
plt.ylabel('Verdadeiro positivo')
plt.title('Curva ROC multiclasse')
plt.legend(loc='lower right')
plt.grid()
plt.show()

model = keras.Sequential()

#camada de entrada
model.add(keras.layers.Conv2D(filters=32,
                              kernel_size=5,
                              strides=(1, 1),
                              padding='same',
                              activation = tf.nn.relu,
                              input_shape=(28,28,1)))
model.add(keras.layers.MaxPool2D(pool_size=(2, 2),
                                 strides=(2, 2),
                                 padding='valid'))

#segunda camada convolucional
model.add(keras.layers.Conv2D(filters=64,
                              kernel_size=3,
                              strides=(1, 1),
                              padding='same',
                              activation=tf.nn.relu))

model.add(keras.layers.MaxPool2D(pool_size=(2, 2),
                                 strides=(2, 2),
                                 padding='valid'))

#adicionar camada de dropout para tentar evitar overlifting
model.add(keras.layers.Dropout(0.25))
model.add(keras.layers.Flatten())

#camada totalmente conectada
model.add(keras.layers.Dense(units=128,
                             activation=tf.nn.relu))
model.add(keras.layers.Dropout(0.5))

#camada de saída
model.add(keras.layers.Dense(units=10, activation=tf.nn.softmax))
model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #expansao das dimensoes para os patamares originais
# X_train = x_train.reshape(60000,28,28,1)
# X_test = x_test.reshape(10000,28,28,1)
# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# model.fit(x=X_train,y=y_train,epochs=5, validation_data=(X_test, y_test), batch_size=128)

test_loss, test_acc=model.evaluate(x=X_test, y=y_test)
print('Acurácia do teste da CNN: %.2f'%test_acc)
print('Perda do teste da CNN: %.2f'%test_loss)

model.save('./model/final_CNN_model.h5')
#model.save('./model/final_CNN_model.keras')
#keras.saving.save_model(model,'final_CNN_model.keras')

from tensorflow.keras.models import load_model
from tensorflow.keras.activations import softmax

#define custom_objects to map the problematic identifier to the correct function
custom_objects = {'softmax_v2': softmax}

new_model = load_model('./model/final_CNN_model.h5', custom_objects=custom_objects)
new_model.summary()

#from tensorflow.keras.models import load_model
#new_model = load_model('./model/final_CNN_model.h5')
#new_model.summary()

# Commented out IPython magic to ensure Python compatibility.
#visualize os resultados da saida do conjunto de testes
# %matplotlib inline
def res_visual(n):
  #faça predição no conjunto de testes usando new_model
  final_opt_a = np.argmax(model.predict(X_test[0:n]), axis=-1)

  #print(final_opt_a)
  fig, ax = plt.subplots(nrows=int(n/5), ncols=5)
  ax = ax.flatten()
  print('Resultados da PREVISÃO das 20 primeiras imagens do conjunto de teste')
  for i in range(n):
    print(final_opt_a[i], end=',')
    if int((i+1)%5) == 0:
      print('\t')

    #vendo as imagens do banco
    img = X_test[i].reshape((28,28))
    plt.axis("off")
    ax[i].imshow(img, cmap='Greys', interpolation='nearest')
    ax[i].axis("off")
  print('primeiras 20 primeiras imagens do conjunto de teste')

res_visual(30)

import streamlit as st
import numpy as np
from tensorflow.keras.models import load_model
from PIL import Image, ImageOps

model = load_model("./model/final_DNN_model.h5")

st.title("CLASSIFICADOR DE DÍGITOS MNIST ")
st.write("Envie uma imagem de um dígito (0 a 9) para o modelo reconhecer.")

uploaded_file = st.file_uploader("Envie sua imagem", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)

    st.image(image, caption="Imagem enviada", width=200)

    image = image.convert("L")
    image = image.resize((28, 28))
    image = ImageOps.invert(image)
    img_array = np.array(image).astype("float32") / 255.0
    img_array = img_array.reshape(1, 784)


    prediction = model.predict(img_array)
    digit = np.argmax(prediction)

    st.subheader(f"DÍGITO PREVISTO: **{digit}**")
    st.write("PROBABILIDADES:")
    st.bar_chart(prediction[0])


#RODANDO O APP.PY NO COMPUTADOR (NN MEXER):
#streamlit run ia2assistido_guilhermemanuel.py & npx localtunnel --port 4580